#!/usr/bin/env python3
"""
ç°¡å˜ãªãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
"""
import torch
import torch.nn.functional as F
import time
import json

def test_model_basic(model_class, model_name, **kwargs):
    """åŸºæœ¬çš„ãªãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ"""
    print(f"\n=== {model_name} ãƒ†ã‚¹ãƒˆ ===")
    
    try:
        # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        model = model_class(**kwargs)
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°
        total_params = sum(p.numel() for p in model.parameters())
        print(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}")
        
        # å°ã•ãªãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        batch_size = 2
        seq_len = 16
        vocab_size = kwargs.get('vocab_size', 100)
        
        input_ids = torch.randint(0, vocab_size, (batch_size, seq_len))
        labels = torch.randint(0, vocab_size, (batch_size, seq_len))
        
        # æ¨è«–é€Ÿåº¦ãƒ†ã‚¹ãƒˆ
        model.eval()
        start_time = time.time()
        
        with torch.no_grad():
            for _ in range(10):  # 10å›å®Ÿè¡Œ
                outputs = model(input_ids, labels=labels)
        
        inference_time = (time.time() - start_time) / 10
        print(f"æ¨è«–æ™‚é–“: {inference_time:.4f}ç§’")
        
        # æå¤±ç¢ºèª
        loss = outputs['loss'].item()
        print(f"åˆæœŸæå¤±: {loss:.4f}")
        print(f"åˆæœŸãƒ‘ãƒ¼ãƒ—ãƒ¬ã‚­ã‚·ãƒ†ã‚£: {torch.exp(outputs['loss']):.2f}")
        
        # ç”Ÿæˆãƒ†ã‚¹ãƒˆ
        test_input = torch.randint(0, vocab_size, (1, 5))
        generated = model.generate(test_input, max_length=15, temperature=1.0)
        print(f"ç”Ÿæˆé•·: {test_input.size(1)} â†’ {generated.size(1)}")
        
        return {
            'model_name': model_name,
            'params': total_params,
            'inference_time': inference_time,
            'initial_loss': loss,
            'initial_perplexity': torch.exp(outputs['loss']).item()
        }
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def main():
    print("ğŸ” ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒãƒ†ã‚¹ãƒˆ")
    
    # å…±é€šè¨­å®š
    config = {
        'vocab_size': 100,
        'd_model': 128,
        'n_layers': 2,
        'max_seq_len': 64
    }
    
    results = []
    
    # å…ƒã®Mambaãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ
    try:
        from mamba_model import MambaModel
        result = test_model_basic(MambaModel, "Original Mamba", **config)
        if result:
            results.append(result)
    except ImportError as e:
        print(f"Original Mambaãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã›ã‚“: {e}")
    
    # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ
    try:
        from hybrid_mamba_model import HybridMambaModel
        hybrid_config = {**config, 'n_heads': 4, 'num_experts': 2}
        result = test_model_basic(HybridMambaModel, "Hybrid Mamba (Mamba+MoE+Transformer)", **hybrid_config)
        if result:
            results.append(result)
    except ImportError as e:
        print(f"Hybrid Mambaãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã›ã‚“: {e}")
    
    # çµæœæ¯”è¼ƒ
    if len(results) >= 2:
        print(f"\nğŸ“Š æ€§èƒ½æ¯”è¼ƒçµæœ")
        print("=" * 60)
        
        orig = results[0]
        hybrid = results[1]
        
        print(f"ãƒ¢ãƒ‡ãƒ«               | ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°    | æ¨è«–æ™‚é–“(ç§’) | åˆæœŸæå¤±  | åˆæœŸPPL")
        print("-" * 60)
        print(f"{orig['model_name']:<20} | {orig['params']:>10,} | {orig['inference_time']:>8.4f} | {orig['initial_loss']:>7.4f} | {orig['initial_perplexity']:>7.2f}")
        print(f"{hybrid['model_name']:<20} | {hybrid['params']:>10,} | {hybrid['inference_time']:>8.4f} | {hybrid['initial_loss']:>7.4f} | {hybrid['initial_perplexity']:>7.2f}")
        
        # æ”¹å–„ç‡è¨ˆç®—
        param_ratio = hybrid['params'] / orig['params']
        time_ratio = hybrid['inference_time'] / orig['inference_time']
        
        print(f"\nğŸ“ˆ æ¯”è¼ƒåˆ†æ:")
        print(f"ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°æ¯”: {param_ratio:.2f}x ({param_ratio-1:+.1%})")
        print(f"æ¨è«–æ™‚é–“æ¯”: {time_ratio:.2f}x ({time_ratio-1:+.1%})")
        print(f"â€»åˆæœŸæå¤±ã¨ãƒ‘ãƒ¼ãƒ—ãƒ¬ã‚­ã‚·ãƒ†ã‚£ã¯æœªè¨“ç·´çŠ¶æ…‹ã§ã®å€¤")
        
    # çµæœä¿å­˜
    with open('model_comparison.json', 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nâœ… ãƒ†ã‚¹ãƒˆå®Œäº†ï¼çµæœã¯model_comparison.jsonã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")

if __name__ == "__main__":
    main()